{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed7e99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install aiohttp\n",
    "#1 time run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from aiohttp import ClientSession\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66417e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiers=[\"IRON\",\"BRONZE\",\"SILVER\",\"GOLD\",\"PLATINUM\",\"EMERALD\",\"DIAMOND\"]\n",
    "divisions = [\"I\", \"II\", \"III\", \"IV\"]\n",
    "pages=[\"1\",\"2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b42421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_save_ranked_players(tiers, divisions, pages):\n",
    "    api_key = \"RGAPI-9700eac4-1e3c-4da8-92d2-d2168387e08f\"  # Use your actual API key\n",
    "    base_url = \"https://euw1.api.riotgames.com/lol/league/v4/entries/RANKED_SOLO_5x5/{tier}/{division}?page={page}\"\n",
    "    headers = {\n",
    "        \"X-Riot-Token\": api_key\n",
    "    }\n",
    "    \n",
    "    file_path = '../DataProcessing/TestData/rankedPlayers.csv'\n",
    "    \n",
    "    with open(file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['tier', 'division', 'summonerName'])  # CSV Header\n",
    "\n",
    "        for tier in tiers:\n",
    "            for division in divisions:\n",
    "                for page in pages:\n",
    "                    url = base_url.format(tier=tier, division=division, page=page)\n",
    "                    response = requests.get(url, headers=headers)\n",
    "\n",
    "                    # Wait for 2 seconds before making the next request\n",
    "                    time.sleep(2)\n",
    "\n",
    "                    if response.status_code == 200:\n",
    "                        players = response.json()\n",
    "                        for player in players:\n",
    "                            if player['wins'] + player['losses'] > 20:\n",
    "                                writer.writerow([player['tier'], player['rank'], player['summonerName']])\n",
    "                    else:\n",
    "                        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "# Note: Before running, replace 'Your_API_Key_Here' with your actual API key and ensure the file path for CSV is correct as per your environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c82a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY RUN IF NEW DATA REQUIRED\n",
    "#made with personal apikey, therefore following personal pullrequest limitation\n",
    "#fetch_and_save_ranked_players(tiers, divisions, pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d848660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for finding dublicates\n",
    "\n",
    "def find_duplicate_summoner_names_with_rows(file_path):\n",
    "    summoner_occurrences = {}  # Tracks summoner names and their row numbers\n",
    "    duplicates_info = []  # Stores information about duplicates\n",
    "\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row_number, row in enumerate(reader, start=1):  # Start counting rows from 1\n",
    "            summoner_name = row['summonerName']\n",
    "            if summoner_name in summoner_occurrences:\n",
    "                # If the summoner name is already encountered, add the current row as a duplicate\n",
    "                summoner_occurrences[summoner_name].append(row_number)\n",
    "            else:\n",
    "                # Otherwise, initialize the list with the current row number\n",
    "                summoner_occurrences[summoner_name] = [row_number]\n",
    "\n",
    "    # Filter out summoner names with more than one occurrence and prepare duplicate info\n",
    "    for summoner_name, row_numbers in summoner_occurrences.items():\n",
    "        if len(row_numbers) > 1:\n",
    "            duplicates_info.append((summoner_name, row_numbers))\n",
    "\n",
    "    return duplicates_info\n",
    "\n",
    "# Specify the file path\n",
    "#file_path = '../DataProcessing/TestData/rankedPlayers.csv'\n",
    "#duplicates = find_duplicate_summoner_names_with_rows(file_path)\n",
    "\n",
    "# Example output\n",
    "#for summoner_name, rows in duplicates:\n",
    "#    print(f\"Duplicate: {summoner_name} found in rows: {rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d303e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for removing dublicates\n",
    "\n",
    "def remove_duplicate_summoner_names(file_path):\n",
    "    processed_summoners = set()  # To track unique summonerNames\n",
    "    unique_rows = []  # To store rows after removing duplicates\n",
    "\n",
    "    # Read the file and filter out duplicate summonerNames\n",
    "    with open(file_path, mode='r', encoding='utf-8') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            if row['summonerName'] not in processed_summoners:\n",
    "                processed_summoners.add(row['summonerName'])\n",
    "                unique_rows.append(row)\n",
    "\n",
    "    # Write the unique rows back to the file\n",
    "    with open(file_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "        fieldnames = ['tier', 'division', 'summonerName']\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(unique_rows)\n",
    "\n",
    "# Specify the file path\n",
    "#file_path = '../DataProcessing/TestData/rankedPlayers.csv'\n",
    "#remove_duplicate_summoner_names(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74df7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_csv_by_tier(source_file_path):\n",
    "    # Define the base folder for the new files\n",
    "    base_folder = os.path.dirname(source_file_path)\n",
    "    \n",
    "    # Initialize a dictionary to keep track of CSV writers for each tier\n",
    "    writers = {}\n",
    "    files = {}\n",
    "    \n",
    "    with open(source_file_path, mode='r', encoding='utf-8') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            \n",
    "            tier = row['tier']\n",
    "            file_name = f\"{tier}_players.csv\"\n",
    "            file_path = os.path.join(base_folder, file_name)\n",
    "            \n",
    "            # Check if we already have a writer for this tier, if not create it\n",
    "            if tier not in writers:\n",
    "                files[tier] = open(file_path, mode='w', newline='', encoding='utf-8')\n",
    "                writers[tier] = csv.DictWriter(files[tier], fieldnames=reader.fieldnames)\n",
    "                writers[tier].writeheader()\n",
    "            \n",
    "            # Write the row to the appropriate file\n",
    "            writers[tier].writerow(row)\n",
    "    \n",
    "    # Close all the files we've opened\n",
    "    for file in files.values():\n",
    "        file.close()\n",
    "\n",
    "# Specify the source file path\n",
    "source_file_path = '../DataProcessing/TestData/rankedPlayers.csv'\n",
    "\n",
    "# Call the function\n",
    "split_csv_by_tier(source_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48658ee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# saves summonernames for further processiing\n",
    "def get_summoner_names_from_csv(file_path):\n",
    "    summoner_names = []\n",
    "    \n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            summoner_names.append(row['summonerName'])\n",
    "    \n",
    "    return summoner_names\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "file_path = '../DataProcessing/TestData/DIAMOND_players.csv'\n",
    "summoner_names = get_summoner_names_from_csv(file_path)\n",
    "print(summoner_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f873ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#personal apikey function, replacing summonernames with puuid\n",
    "#FINDS PUUID FROM SUMMONER NAME\n",
    "def update_summoner_names_with_puuid(file_path, summoner_names):\n",
    "    api_key = \"RGAPI-f1974148-4124-4d03-92aa-b1508bcca232\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"da-DK,da;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "        \"Accept-Charset\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\": \"https://developer.riotgames.com\",\n",
    "        \"X-Riot-Token\": api_key\n",
    "    }\n",
    "    summoner_to_puuid = {}\n",
    "\n",
    "    start_time = time.time()\n",
    "    last_update_time = start_time\n",
    "    total_names = len(summoner_names)\n",
    "    names_processed = 0\n",
    "\n",
    "    # Fetch puuid for each summoner name\n",
    "    for name in summoner_names:\n",
    "        url = f\"https://euw1.api.riotgames.com/lol/summoner/v4/summoners/by-name/{name}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            summoner_to_puuid[name] = data['puuid']\n",
    "        else:\n",
    "            print(f\"Error fetching data for {name}: {response.status_code}\")\n",
    "        names_processed += 1\n",
    "        current_time = time.time()\n",
    "\n",
    "        # Check if 1 minute has passed for progress update\n",
    "        if current_time - last_update_time >= 60:\n",
    "            print(f\"Progress: {names_processed}/{total_names} summoner names processed.\")\n",
    "            last_update_time = current_time\n",
    "\n",
    "        time.sleep(1.5)  # Delay to comply with rate limit\n",
    "    \n",
    "    # Update progress after finishing all requests\n",
    "    print(f\"Progress: {names_processed}/{total_names} summoner names processed. Update complete.\")\n",
    "\n",
    "    # Now, replace summoner names with puuid in the CSV\n",
    "    temp_file_path = file_path + \".tmp\"\n",
    "    with open(file_path, mode='r', encoding='utf-8') as infile, open(temp_file_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in reader:\n",
    "            if row['summonerName'] in summoner_to_puuid:\n",
    "                row['summonerName'] = summoner_to_puuid[row['summonerName']]\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    # Replace original file with the updated temp file\n",
    "    os.replace(temp_file_path, file_path)\n",
    "\n",
    "\n",
    "# Call the function\n",
    "update_summoner_names_with_puuid(file_path, summoner_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e12b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINDS PUUID FROM SUMMONER NAME v2\n",
    "#with production key\n",
    "async def fetch_puuid(session, url, headers, semaphore, summoner_to_puuid, name):\n",
    "    async with semaphore:\n",
    "        async with session.get(url, headers=headers) as response:\n",
    "            if response.status == 200:\n",
    "                data = await response.json()\n",
    "                summoner_to_puuid[name] = data['puuid']\n",
    "            else:\n",
    "                print(f\"Error fetching data for {name}: {response.status}\")\n",
    "\n",
    "async def rate_limited_requester(summoner_names, headers, rate_limit=30):\n",
    "    tasks = []\n",
    "    summoner_to_puuid = {}\n",
    "\n",
    "    semaphore = asyncio.Semaphore(rate_limit)\n",
    "\n",
    "    async with ClientSession() as session:\n",
    "        for name in summoner_names:\n",
    "            url = f\"https://euw1.api.riotgames.com/lol/summoner/v4/summoners/by-name/{name}\"\n",
    "            task = asyncio.create_task(fetch_puuid(session, url, headers, semaphore, summoner_to_puuid, name))\n",
    "            tasks.append(task)\n",
    "\n",
    "            if len(tasks) % rate_limit == 0:\n",
    "                await asyncio.sleep(1)\n",
    "\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "    return summoner_to_puuid\n",
    "\n",
    "async def update_summoner_names_with_puuid(file_path, summoner_names):\n",
    "    api_key = \"RGAPI-e75b46d3-5e51-4829-b978-68790c3ebf56\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"da-DK,da;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "        \"Accept-Charset\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\": \"https://developer.riotgames.com\",\n",
    "        \"X-Riot-Token\": api_key\n",
    "    }\n",
    "\n",
    "    summoner_to_puuid = await rate_limited_requester(summoner_names, headers)\n",
    "\n",
    "    temp_file_path = file_path + \".tmp\"\n",
    "    with open(file_path, mode='r', encoding='utf-8') as infile, open(temp_file_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in reader:\n",
    "            if row['summonerName'] in summoner_to_puuid:\n",
    "                row['summonerName'] = summoner_to_puuid[row['summonerName']]\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    os.replace(temp_file_path, file_path)\n",
    "\n",
    "# Execution block adapted for Jupyter Notebook\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "#source_csv_path = \"../DataProcessing/TestData/GOLD_players.csv\"\n",
    "\n",
    "\n",
    "if loop.is_running():\n",
    "    task = loop.create_task(update_summoner_names_with_puuid(source_csv_path, summoner_names))\n",
    "else:\n",
    "    loop.run_until_complete(update_summoner_names_with_puuid(source_csv_path, summoner_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf2cb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds matches from puuid\n",
    "# personal api key function\n",
    "def fetch_matches_and_save(source_csv_path, target_csv_path):\n",
    "    api_key = \"RGAPI-8840c4e8-ef3d-40cb-90fa-2ea005f2bb1c\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"da-DK,da;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "        \"Accept-Charset\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\": \"https://developer.riotgames.com\",\n",
    "        \"X-Riot-Token\": api_key\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    last_update_time = start_time\n",
    "    summoners_processed = 0\n",
    "\n",
    "    # Ensure the target file directory exists\n",
    "    os.makedirs(os.path.dirname(target_csv_path), exist_ok=True)\n",
    "\n",
    "    with open(source_csv_path, mode='r', encoding='utf-8') as infile, open(target_csv_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "        csv_reader = csv.DictReader(infile)\n",
    "        csv_writer = csv.writer(outfile)\n",
    "        csv_writer.writerow(['MatchID'])  # Header for target CSV\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            puuid = row['summonerName']  # Assuming this column actually contains puuids\n",
    "            url = f\"https://asia.api.riotgames.com/lol/match/v5/matches/by-puuid/{puuid}/ids?type=ranked&start=0&count=20\"\n",
    "            response = requests.get(url, headers=headers)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                match_ids = response.json()\n",
    "                for match_id in match_ids:\n",
    "                    csv_writer.writerow([match_id])\n",
    "            else:\n",
    "                print(f\"Error fetching matches for {puuid}: {response.status_code}\")\n",
    "            \n",
    "            summoners_processed += 1\n",
    "            current_time = time.time()\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(1.5)\n",
    "            \n",
    "            # Print progress every minute\n",
    "            if current_time - last_update_time >= 60:\n",
    "                print(f\"Progress: {summoners_processed} summoners processed.\")\n",
    "                last_update_time = current_time\n",
    "\n",
    "    # Final progress update\n",
    "    print(f\"Final Progress: {summoners_processed} summoners processed. Task complete.\")\n",
    "\n",
    "# Example usage\n",
    "source_csv_path = '../DataProcessing/TestData/DIAMOND_players_korea.csv'\n",
    "target_csv_path = '../DataProcessing/TestData/DIAMOND_GAMES_KOREA.csv'\n",
    "fetch_matches_and_save(source_csv_path, target_csv_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e21f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds dublicate matches\n",
    "def print_duplicates(csv_file_path):\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Identifying all duplicates, including the first occurrence\n",
    "    duplicates = df[df.duplicated('MatchID', keep=False)]\n",
    "    \n",
    "    # Group by 'MatchID' and aggregate the indexes into a list\n",
    "    grouped_duplicates = duplicates.groupby('MatchID').apply(lambda x: list(x.index))\n",
    "    \n",
    "    # Check if duplicates are found\n",
    "    if not grouped_duplicates.empty:\n",
    "        print(\"Duplicate MatchIDs found along with their locations (indexes):\")\n",
    "        for match_id, indexes in grouped_duplicates.items():\n",
    "            print(f\"MatchID: {match_id}, Indexes: {indexes}\")\n",
    "    else:\n",
    "        print(\"No duplicate MatchIDs found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f117dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing all dublicate matches\n",
    "import pandas as pd\n",
    "def remove_duplicates_and_save(csv_file_path, output_file_path):\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Remove duplicates based on the 'MatchID' column and keep the first occurrence\n",
    "    cleaned_df = df.drop_duplicates('MatchID', keep='first')\n",
    "    \n",
    "    # Save the cleaned DataFrame to a new CSV file\n",
    "    cleaned_df.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    print(f\"Cleaned CSV saved to {output_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36043f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example usage\n",
    "#csv_file_path='../DataProcessing/TestData/DIAMOND_GAMES_KOREA.csv'\n",
    "#output_file_path='../DataProcessing/TestData/CLEANED_DIAMOND_GAMES_KOREA.csv'\n",
    "#remove_duplicates_and_save(csv_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b389698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to save whole response body riot api timeline\n",
    "#edit url to desired api url\n",
    "def call_api_and_save_response_with_progress(csv_file_path, save_folder_path):\n",
    "    # Define the base URL and headers for the API call\n",
    "    base_url = \"https://asia.api.riotgames.com/lol/match/v5/matches/\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"da-DK,da;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "        \"Accept-Charset\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\": \"https://developer.riotgames.com\",\n",
    "        \"X-Riot-Token\": \"RGAPI-e75b46d3-5e51-4829-b978-68790c3ebf56\"\n",
    "    }\n",
    "    \n",
    "    # Read Match IDs from the CSV file\n",
    "    with open(csv_file_path, mode='r', newline='', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        match_ids = [row['MatchID'] for row in csv_reader]\n",
    "    \n",
    "    total_matches = len(match_ids)\n",
    "    matches_processed = 0\n",
    "    start_time = time.time()\n",
    "    last_update_time = start_time\n",
    "\n",
    "    # Process each Match ID\n",
    "    for match_id in match_ids:\n",
    "        full_url = base_url + match_id + \"/timeline\"\n",
    "        \n",
    "        # Make the API call\n",
    "        response = requests.get(full_url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            # Save the response body as a JSON file\n",
    "            file_path = os.path.join(save_folder_path, f\"{match_id}.json\")\n",
    "            with open(file_path, 'w', encoding='utf-8') as json_file:\n",
    "                json.dump(response.json(), json_file, ensure_ascii=False, indent=4)\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for Match ID {match_id}. Status Code: {response.status_code}\")\n",
    "        \n",
    "        matches_processed += 1\n",
    "        \n",
    "        # Respect the API rate limit\n",
    "        time.sleep(1/30)  # Sleep to ensure not exceeding 30 calls per second\n",
    "        \n",
    "        current_time = time.time()\n",
    "        if current_time - last_update_time >= 60:\n",
    "            print(f\"Processed {matches_processed}/{total_matches} matches. {int((matches_processed/total_matches)*100)}% complete.\")\n",
    "            last_update_time = current_time\n",
    "    \n",
    "    # Final update\n",
    "    print(f\"All {total_matches} matches processed. 100% complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c13fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for calling and saving responsebody from postmatch data api\n",
    "def fetch_and_save_match_data(csv_file_path, output_folder_path):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Accept-Charset\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\": \"https://developer.riotgames.com\",\n",
    "        \"X-Riot-Token\": \"RGAPI-e75b46d3-5e51-4829-b978-68790c3ebf56\"\n",
    "    }\n",
    "\n",
    "    if not os.path.exists(output_folder_path):\n",
    "        os.makedirs(output_folder_path)\n",
    "\n",
    "    # Count total MatchIDs in the CSV file\n",
    "    with open(csv_file_path, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        total_ids = sum(1 for row in reader)\n",
    "\n",
    "    # Reset file pointer to start\n",
    "    with open(csv_file_path, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        current_position = 0\n",
    "        for row in reader:\n",
    "            match_id = row[0]\n",
    "            url = f\"https://asia.api.riotgames.com/lol/match/v5/matches/{match_id}\"\n",
    "\n",
    "            response = requests.get(url, headers=headers)\n",
    "            current_position += 1\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                output_file_path = os.path.join(output_folder_path, f\"{match_id}.json\")\n",
    "                with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "                    outfile.write(response.text)\n",
    "            else:\n",
    "                print(f\"Failed to fetch data for MatchID: {match_id}, Status Code: {response.status_code}\")\n",
    "\n",
    "            # Progress update\n",
    "            if current_position % 250 == 0 or current_position == total_ids:  # Update every 250 requests or on last request\n",
    "                print(f\"Progress: {current_position}/{total_ids}\")\n",
    "\n",
    "            time.sleep(1 / 30)  # Respect the rate limit\n",
    "\n",
    "    print(f\"Finished processing. Total requests: {current_position}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
