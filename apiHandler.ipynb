{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ed7e99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiohttp in c:\\users\\johan\\anaconda3\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\johan\\anaconda3\\lib\\site-packages (from aiohttp) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\johan\\anaconda3\\lib\\site-packages (from aiohttp) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\johan\\anaconda3\\lib\\site-packages (from aiohttp) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\johan\\anaconda3\\lib\\site-packages (from aiohttp) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\johan\\anaconda3\\lib\\site-packages (from aiohttp) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\johan\\anaconda3\\lib\\site-packages (from aiohttp) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\johan\\anaconda3\\lib\\site-packages (from aiohttp) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\johan\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66417e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiers=[\"IRON\",\"BRONZE\",\"SILVER\",\"GOLD\",\"PLATINUM\",\"EMERALD\",\"DIAMOND\"]\n",
    "divisions = [\"I\", \"II\", \"III\", \"IV\"]\n",
    "pages=[\"1\",\"2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d9862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://developer.riotgames.com/apis#summoner-v4/GET_getBySummonerName\n",
    "#https://developer.riotgames.com/apis#match-v5/GET_getMatchIdsByPUUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b42421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import time  # Import the time module\n",
    "\n",
    "def fetch_and_save_ranked_players(tiers, divisions, pages):\n",
    "    api_key = \"RGAPI-9700eac4-1e3c-4da8-92d2-d2168387e08f\"  # Use your actual API key\n",
    "    base_url = \"https://euw1.api.riotgames.com/lol/league/v4/entries/RANKED_SOLO_5x5/{tier}/{division}?page={page}\"\n",
    "    headers = {\n",
    "        \"X-Riot-Token\": api_key\n",
    "    }\n",
    "    \n",
    "    file_path = '../DataProcessing/TestData/rankedPlayers.csv'\n",
    "    \n",
    "    with open(file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['tier', 'division', 'summonerName'])  # CSV Header\n",
    "\n",
    "        for tier in tiers:\n",
    "            for division in divisions:\n",
    "                for page in pages:\n",
    "                    url = base_url.format(tier=tier, division=division, page=page)\n",
    "                    response = requests.get(url, headers=headers)\n",
    "\n",
    "                    # Wait for 2 seconds before making the next request\n",
    "                    time.sleep(2)\n",
    "\n",
    "                    if response.status_code == 200:\n",
    "                        players = response.json()\n",
    "                        for player in players:\n",
    "                            if player['wins'] + player['losses'] > 20:\n",
    "                                writer.writerow([player['tier'], player['rank'], player['summonerName']])\n",
    "                    else:\n",
    "                        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "# Note: Before running, replace 'Your_API_Key_Here' with your actual API key and ensure the file path for CSV is correct as per your environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c82a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY RUN IF NEW DATA REQUIRED\n",
    "#fetch_and_save_ranked_players(tiers, divisions, pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d848660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def find_duplicate_summoner_names_with_rows(file_path):\n",
    "    summoner_occurrences = {}  # Tracks summoner names and their row numbers\n",
    "    duplicates_info = []  # Stores information about duplicates\n",
    "\n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row_number, row in enumerate(reader, start=1):  # Start counting rows from 1\n",
    "            summoner_name = row['summonerName']\n",
    "            if summoner_name in summoner_occurrences:\n",
    "                # If the summoner name is already encountered, add the current row as a duplicate\n",
    "                summoner_occurrences[summoner_name].append(row_number)\n",
    "            else:\n",
    "                # Otherwise, initialize the list with the current row number\n",
    "                summoner_occurrences[summoner_name] = [row_number]\n",
    "\n",
    "    # Filter out summoner names with more than one occurrence and prepare duplicate info\n",
    "    for summoner_name, row_numbers in summoner_occurrences.items():\n",
    "        if len(row_numbers) > 1:\n",
    "            duplicates_info.append((summoner_name, row_numbers))\n",
    "\n",
    "    return duplicates_info\n",
    "\n",
    "# Specify the file path\n",
    "#file_path = '../DataProcessing/TestData/rankedPlayers.csv'\n",
    "#duplicates = find_duplicate_summoner_names_with_rows(file_path)\n",
    "\n",
    "# Example output\n",
    "#for summoner_name, rows in duplicates:\n",
    "#    print(f\"Duplicate: {summoner_name} found in rows: {rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d303e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def remove_duplicate_summoner_names(file_path):\n",
    "    processed_summoners = set()  # To track unique summonerNames\n",
    "    unique_rows = []  # To store rows after removing duplicates\n",
    "\n",
    "    # Read the file and filter out duplicate summonerNames\n",
    "    with open(file_path, mode='r', encoding='utf-8') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            if row['summonerName'] not in processed_summoners:\n",
    "                processed_summoners.add(row['summonerName'])\n",
    "                unique_rows.append(row)\n",
    "\n",
    "    # Write the unique rows back to the file\n",
    "    with open(file_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "        fieldnames = ['tier', 'division', 'summonerName']\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(unique_rows)\n",
    "\n",
    "# Specify the file path\n",
    "#file_path = '../DataProcessing/TestData/rankedPlayers.csv'\n",
    "#remove_duplicate_summoner_names(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb98cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def split_csv_by_gold_tier(source_file_path):\n",
    "    # Define the base folder for the new files\n",
    "    base_folder = os.path.dirname(source_file_path)\n",
    "    \n",
    "    # Initialize a dictionary to keep track of the CSV writer for the GOLD tier\n",
    "    writer = None\n",
    "    file = None\n",
    "    \n",
    "    with open(source_file_path, mode='r', encoding='utf-8') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            tier = row['tier']\n",
    "            \n",
    "            # Proceed only if the tier is GOLD\n",
    "            if tier == \"PLATINUM\":\n",
    "                file_name = \"PLATINUM_players.csv\"\n",
    "                file_path = os.path.join(base_folder, file_name)\n",
    "                \n",
    "                # Check if we already have a writer for the GOLD tier, if not, create it\n",
    "                if writer is None:\n",
    "                    file = open(file_path, mode='w', newline='', encoding='utf-8')\n",
    "                    writer = csv.DictWriter(file, fieldnames=reader.fieldnames)\n",
    "                    writer.writeheader()\n",
    "                \n",
    "                # Write the row to the GOLD file\n",
    "                writer.writerow(row)\n",
    "    \n",
    "    # Close the file for the GOLD tier if it's open\n",
    "    if file is not None:\n",
    "        file.close()\n",
    "\n",
    "# Specify the source file path\n",
    "source_file_path = '../DataProcessing/TestData/rankedPlayers.csv'\n",
    "\n",
    "# Call the function\n",
    "split_csv_by_gold_tier(source_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a74df7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_csv_by_tier(source_file_path):\n",
    "    # Define the base folder for the new files\n",
    "    base_folder = os.path.dirname(source_file_path)\n",
    "    \n",
    "    # Initialize a dictionary to keep track of CSV writers for each tier\n",
    "    writers = {}\n",
    "    files = {}\n",
    "    \n",
    "    with open(source_file_path, mode='r', encoding='utf-8') as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            \n",
    "            tier = row['tier']\n",
    "            file_name = f\"{tier}_players.csv\"\n",
    "            file_path = os.path.join(base_folder, file_name)\n",
    "            \n",
    "            # Check if we already have a writer for this tier, if not create it\n",
    "            if tier not in writers:\n",
    "                files[tier] = open(file_path, mode='w', newline='', encoding='utf-8')\n",
    "                writers[tier] = csv.DictWriter(files[tier], fieldnames=reader.fieldnames)\n",
    "                writers[tier].writeheader()\n",
    "            \n",
    "            # Write the row to the appropriate file\n",
    "            writers[tier].writerow(row)\n",
    "    \n",
    "    # Close all the files we've opened\n",
    "    for file in files.values():\n",
    "        file.close()\n",
    "\n",
    "# Specify the source file path\n",
    "source_file_path = '../DataProcessing/TestData/rankedPlayers.csv'\n",
    "\n",
    "# Call the function\n",
    "split_csv_by_tier(source_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48658ee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lil Pump', '3XpEnDaBlE', 'Wickly', 'MrScene', 'drombom', '2JZ SINGLE TURBO', 'Benwailord2', 'YA ISEIKYA', 'TRASHDRAVENXD', 'Mr  Puff', 'PIBAB DE KEBZA', 'zozoricardo', 'Lana Del Ahrey', 'Nogitsune101', 'Death13n2', 'Matthicc', 'aleix4444', 'Yuuriko', 'KaNeKi       0', 'GCB G2 SurbEnzo', 'SOLO SINGED', 'Jajacubu', 'JugoJugovice', 'StarGuardianAdc', 'MAZĘ', 'HitMeBaby1', 'XSoulh', 'Dešreliu Uogiene', 'Dolboyob', 'F9Smôkey', 'Titeuf V2', 'Petrichoria', 'Sisoo', 'KATABLOOD', 'Not Genji', 'Revolution 909', 'VKJ', 'Mudda Simon', 'carlos larios', 'S K I N E U R E', 'Milchryze', 'R6Ezio', 'jsuis p2 nero', 'PFP Paulux', 'CordeWow', 'Hawk280', 'Nevia', 'YasTraining666', 'GoldChronos', 'Teddybaer2901', 'luucaasssss', 'Xulaxe12', 'LethalFoxdiver', 'Mo4ning Myrtle', 'biao jiu ya', 'sina3es', 'ProductionsZ', 'Uraxee', 'Zazlost', 'Windie the Pooh', 'Emil Schöer', 'Hyper boner', 'MET4 ABUSER', 'Trippy Mane', 'Shactas', 'bocata pollo GOZ', 'Cha0sVal3ri0', 'UdoVonNebenan', 'Lσst Hope', '0tt0o', 'Nοst', 'Hook or Tumble', 'Tarsan', 'Rocket Admin Mon', 'Wat3Elemental', 'orejis', 'G2 Riko', 'RYUNJIN', 'Rasket12', 'LNC Howl', 'Bernie SandAss', 'Asuke', 'MrVenom76', 'Scsilveer', 'Lebensgepferd', 'GhostLotus7', 'Öttinger Export', 'spark ashes', 'Shineo', 'Whispii', 'OG LUFFY10', 'jynersej123', 'a7medZyZ', 'LS SUSHI', 'Taboooo', '911Enjoyerr', 'Egyptisch Sletje', 'relltiH', 'masterpere', 'Take My Ass', '3xtraLife', 'Chtiwa Rabe', 'DADDYWECANT', 'JustSømeone', 'IAA KillerLight', 'RITO Nabius', 'Raclo Grotesque', 'League0fTrol', 'LosingMyReligion', 'SrFrente', 'PatroFaker', 'Løtus Bloom', 'ABADAS0', 'K3wb', 'BotKazu', 'KiertolaisPotku', 'Statsh', 'Dj Butragueño', 'Rodrigodi', 'Astfer', 'NorDag', 'Gm la moustache', 'KappaIgnaz', 'HW Varus', 'CallOfOscar', 'dPrr', 'Horsban', 'Metsae1', 'BoostingTheNoob', 'Jabzzz', 'Why Loss', 'Berserink', 'Grobmotoriker', 'IceBornLissandra', 'TDS Velkoz', 'BenniW2006', 'wrist', 'Jieus', 'Scouting ViJanna', 'ζξζ ιuciifer', 'Hymn For Weekend', 'Trick 187', 'PowerliftingGod', 'Gorfo Pérsico', 'WalkerGTA', 'CookieKi11er', 'D7 pipitoo', 'OTP Bzzz Bzz Bzz', 'FadyBot', 'F3mboy4TrenUser', 'QueDuSaleee', '97x7', 'lucozayd', 'Vexican', 'SltcleBoJeu', 'Starkiller963', 'MCelik7', 'Sebbisalo', 'zeyadGR', 'His airnessss', 'EXC Cracky', 'TMG Rat', 'kusobaaan', 'GoÐLiKee', 'WayBackHome', 'Speed Feeder', 'ΔŁT3R EGΘ', 'MisChollegh', 'Purrisa', 'Oli0708', 'Baumard', 'Vegvísir', 'pumuaser', 'vlad333pro', '1v9 BOOSTED XDXD', '5 Eight', 'JJ Fan Number 1', 'Bekando', 'Atrocis', '187cm 100kg 44cm', 'Yuki no hana', 'ZiNeXeN', 'LolCausa13', 'buff kat pls', 'SacrebIew', 'Modmoody69', 'Rastapouloss', 'WillAfkIfYouFeed', 'Μatimute', 'Sit 0n My Jayce', 'ƒrostii', 'xMayor', 'LordGoetz', 'JeyBiKey660', 'Reavølt', 'Tejuwa', 'SayderLover', 'GodRollsRoyce', 'D0PAMIN3', 'Shen Eilish', 'KC Kaizen', 'Aatrocs', 'sindol', 'fasgen', 'Zirooo', 'ISO Hoster', 'JL Jhinalee', '6th7th', 'KabansBratan', 'Thressh Or AFK', 'Υuumi Is AFK', 'Dr Ludwig', 'Elhas Teeze', 'LL Shadow21', 'Bottom Dog', 'UTOPIAN JUNGLE', 'IngenieurFtassa', 'Goldbluete', 'DontTouchMyBuffs', 'Arzem', 'Welbley', 'roseblack1', 'lilakartoffel13', 'TheLiquidprancks', 'sageshadowblade', 'fartprincess', 'Ghaith BM', 'PBJ Thorn', 'BaboucheZ', 'G2 Ardi', 'VenoXSeFi', 'NPZ Θbn0xious', 'Kuro Thresh V2', 'Nightkols', 'Ostium803', 'LC Slâughter', 'Nolpforvlad', 'x Se7en x', 'Pluie2semance', 'DiscGolfKing', 'Arnold Rthstein', 'RLB Willy Wonka', 'NOT JusticarPT', 'Swift202', 'Sparka Spädbarn', 'HiKaRuuuuu', 'dali 18', 'Elysian Lucifer', 'Puki style83', 'Egirl Happyp', 'Zeri Chance', 'Asians Invasion', 'Akali 1', 'Bowaq', 'ßodî', 'obzii', 'Ruhestörer', 'lets smile', 'PKP Snow', 'Zed Ultime', 'Martyno92', 'BlinkInBack', 'Nemesis Yasuo', 'Emirjan', 'idek cba', 'BEN ILias Ladon', 'S4CHIN', 'WafiFanGirls', 'NamelessKing0', 'K423Kv2', 'OopsWrongBuild', 'Stoppschild', 'CruizAider', 'Le Garen berbère', 'Vallkill', 'QGINM', 'GameIsRiggedJng', 'TwengoHengo', 'UnfireBird', 'Briar Lover', 'Khile', 'DLegendDikidik', 'LeRoiJOJOJ', 'Kayuet', 'marcosto', 'FruitlessPage', 'Khada Jhîή', 'G2 StopAsianHate', 'xXSilazoXx', 'Siiika', 'Jynck', 'New Zealand', 'ˆSpaceglider', 'TSW B4lrog', 'nicolaunoob', 'Marsymenchen', 'Karma ad nauseam', 'MiTodaDevoro', 'Fais les drakes', 'Acnologıa', 'Mitsubishi Motor', 'Killerjake1313', 'Bellini', 'Dlck Tektiv', 'Otiti', 'BERSERKER OZ', 'EeuwigeMaagd', 'DamnItsmeagain', 'ryski', 'Ω VØID Ω', 'BoaBIgCook', 'Don Hentai', 'CheapGumayusi', 'JacquieMichelTV2', 'Frex0', 'DisgustinJGL', 'mofado', 'TheRealCraze', 'Fabula Aeternum', 'Artistá', 'Mer1in0', 'Judia Tétrica', 'acoustic support', 'MyTeamAreMonkeys', 'R3portJungler', 'Crέάmπ', 'Jowyth', 'PaddelAnka', 'Pivasik', 'Her good servant', 'Vankell', 'Sparapoppo01', 'OGLS', 'DreamsTaken', 'L1v1ng D0ll', 'Egirl x Lillia', 'playthecooookie', 'RaptorTex', 'fantoski', 'CorpseWithASoul', 'CleptoMain', 'pedariboi', 'Terkalis', 'PROJET DWITCH', 'liamesto', 'Darktilles', 'sick of love', 'Insane lux', 'winni witch', 'Fearrrr', 'SoloLanerSpecial', 'Golden La Chupo', 'PerfectExecuti0n', '7ohne', 'Δ Nox', 'MYØ', 'Guïtoü', 'AreWeGettinPaid', 'Mivas6', 'Rivive', 'BriarToesPics', 'RzphiHOW', 'zivenbrown', 'DazzdouzA', 'BeeingShapeD TTV', 'THΞ WØRST', 'Felix mag Pepsi', 'yfugvhabjzkaqzn', 'pl0skN', 'Schnitzelking33', 'kiliminedanga', 'Drewniak25', 'DerGeeIzDaaa', 'Edgy Incel', 'OWL Kira', 'Hororoi', 'Fake Toph', 'Kíng Leonídas', 'MaxMillluis', 'vlad t0 meet you', '1YasuOTP1', 'muteall addict', 'tutsy34', 'Ja loei lief', 'SHEEEÂymaneEEESH', 'KC NASSER', 'Jojokem', 'BakouSmileA7mer', 'yondaeme', 'Bali8', 'da me boost bro', 'DEMET AKALIN', 'BARK ADDICTED', 'NΟ ENNEMIES', 'Sheyo', 'nigzz', 'RedStormKata', 'GGsFamily', 'GetBlue', 'KC Alder', 'RiVAH', 'Memes Huelva 2', 'GlowingRay', 'Hidejirô', 'bbyboy', 'seekers521', 'leesingasong', 'SparecchioTavoli', 'Neelianae', '4krad Maroc YTB', '347maurice', 'LopiCast', 'JeCPasCeKeJeFais', 'Scrypless', 'madlove', 'Dieu Roi Tétons', 'Zipheria', 'bylopex', 'Not GP Main', 'Mustashi', 'DaktarasKirvis', 'D R A V E N  MG1', 'MRxandre2006', 'Icehowl Reformed', 'Parkieciarz', 'OsamaBeenLaughin', 'Merukasan', 'Zello75', 'Rocket2412', 'Rextip', 'fjwonder974', 'WowoBE', 'Preveder', 'Punisher ARA', 'DripWalterWhite', 'DE Gumayusi', 'CallMeDanny', 'she didnt fix me', 'Mr Sirou', 'Αeon', 'LadyUnicorn13', 'Archeeeee', 'W4ert', 'POSITIVE MlNDSET', 'KîngJames', 'G2 Flhin', 'carmonillo', 'F1orgive Me', 'EUNE Bronze Guy', 'Zanzaraah', 'Orangedx', 'DonGemelin', 'Regular Pyke', 'HoowTooPlaay', 'mordetrox', 'LGG SYNDICATE', 'FindaBook', 'Ravagax Le Brun', 'Waddles', 'Rizzaldinho', 'TechTheMighty', 'sLucians', 'AMG E55', 'arkadia452', 'Suiako', 'Anluxy', 'The2econdAveng3r', 'ShAhZaDa', 'skowie8', 'Țidecaller', 'flowerthe1st', 'Boön', 'harpooη', 'ToyotaYaris', 'Rygyel', 'Le Popax', 'Jοe Rogan', 'SousWeedLaCassio', 'Ëagle eye', 'Phinks Hanma', 'izanra1105', 'Muay Thai LeeSln', 'El Jorge OMG', 'Majixl', 'Happy Nudo', 'NAWESS59', 'Bombira', 'tell me how', 'Catarińa', 'MidLane go brrrr', 'BARRAS BRAVASS', 'Kirilal', 'Mister Kyu', 'Crazyouuuu', 'Suck Foraka', 'papy glaçon', 'ASHE O CLITORIS', 'TahmaTiger', 'alatum0', 'dirtytales', 'JMM Voxi', 'Monkeyss', 'baumboi', 'mäxlemauer', 'Le PatopurifiK', 'Ellermann', 'karonalife', 'Vøffe', 'I am JhinMCqueen', 'I3luex3', 'Filthy Pranks', 'Massafghanistan', 'zBuddha', 'SimoDXD06', 'GanjaMan02', 'K0mpY', 'Choupette2323', 'Deehan1', 'BlackRe4cher', 'LilTitu', 'KC SUKUNA', 'Shishi', 'Poutou Gaped', 'V the thug V', 'm4kOnkY', 'junjiezou', 'm1keγ', 'elmelenas19', 'solomun fanboy', 'ReekPaTeet', 'WinDroseeN', 'WªsteMªnªgemeπt', 'Tardes', 'Sharphik', 'Kiviks Musteri', 'Auron011', 'Samiz', 'PROUDCATOWNER', 'DeMoonSlayer', 'ramanujan22', 'OrangeRequiem', 'Flixibus', 'yasfas22', 'Akally the Mommy', 'lordmariscal', 'Frαmboos', 'BronzeKikoulol', 'ExoLioco', 'kasaitaitan', 'GIGACHADSLE6', 'filthy hook', 'CAKS Hervé NRV', 'Grafft', 'dignumb', 'Odoroki', 'Tiramizou', 'KattKrystal', 'XxHawkEyexX2', 'Satσru Gσjσ', 'Malaikah', 'SP 0K4M1', 'THEELITEDUMMY', 'r10FeelMyStyle', 'ChuckMorris420', 'Standef1', 'Vgf Bobler', 'KayzLow', 'Kaynywest007', 'Ønly For You', 'LastmekPatron', 'TsuTεy', 'ReLLeUm77', 'Compared Child', 'Mr Brâve', 'Sarciaaa', 'karhqo', 'LKA', 'N0thingMuch', 'XAU ELO', 'rayy3n', 'ITDG Nobo', 'ertines', 'SEOUL REFORMED', 'uJMerlinZ', 'miyuukî', 'Acol', 'LastExilePS', 'TETΔS EDGY', 'Sultan Djinet', 'Matjack', 'Popfitz', 'Tréning LIFE', 'Serilum', 'Kite MachinΣ', 'xDalogg03', 'ethanjem', 'IRELIADASH', 'Danishboy1', 'Unkreativie Chan', 'FishermanThrêsh', 'Nowadays', 'LittleBadPuppy', 'Le Denk', 'CallMeRogue', 'Cha Jeong Woo', 'Emirald', 'V HarmaN V', 'Cheetobreath', 'stinkymorgulrat', 'Kira Nightfall', 'thalliste', 'MelekLégère', 'Double D Sarahh', 'Xéfar', 'Kimmie Possible', 'ladysreaper', 'totobrother1', 'GotNoJuice', 'Andrew Cake', 'Meto The Avatar', 'decami', 'Twososuso', 'Hephaistos722', 'SchlaegerCarlos1', 'Fullbusterx', 'NobodyEscapesss', 'Verssyl', 'serpenvif', 'infinte player', 'Viajante Meep', 'LeTöm', 'unT1lll', 'AlexCorpa01', '69 KlLLER', 'LeLOucH Vi PriDe', 'The Ruined 22', 'GravityControl', 'LOT Omega', 'Vulcannized', 'Skyline AEM', 'maselDoff', 'NoSee', 'GGracchus', 'LUNA ΚΙ', 'neuc', 'Eze le Croquette', 'Xayah For U', 'juniornN', 'Lord Axt', 'RXKIM', 'oryxkiller', 'MainerMain', 'DrChromie', 'FNC BENNA', 'HoKinn10', 'FLØRØ', 'DestructorCat', 'Zenitsuo', 'SnoopDogDeluxe', 'Markiyoo', 'MitsuKuma', 'helz', 'Høyfyren', 'Dèdalo', 'Freshmiets', 'HaveNoEnemiess', 'Rhoast', 'FLECHADUR XL', 'Machine à fumée', 'RK Beelze', 'Kµngs', 'łł Δlex łł', 'Mισ', 'fieryce', 'LoliNEET Kazuma', 'Ninth Hell', 'WGT fatguytop', 'MrBanane', 'xMedicalStudentx', 'Olsen153', 'Ûnnormal', 'Godzu', 'GioChips', 'PolRamos', 'VinyPlane', 'PtiripouSpécial', 'SafinuX Prime', 'Alex YanL', 'Sadisman', '00 SCHNIPPI 00', 'Beware of Shadow', 'ShiroTaiga', 'LoGxLoe', 'Hoomz', 'χ ηaoκo χ', 'Xideneeb', 'xTheNot', 'Sazky', 'TTM120', 'SisterF1ster69', 'JesusTrinkus', 'hasta la tranca', 'CAPTAINH0N0RME', 'Mitsuko Sôma', 'genja12345', 'PaisenKun', 'Chikchikuaua', 'AresCrono', 'brutzelbro', 'Ajjuma', 'TaktischesGehirn', 'full in fiesta', 'JUJANG', 'ABD Donald Trump', 'FB Ravenous', 'AKtoToJestRambo', 'Mid Kingdomm', 'xGG GaMeR', 'mnqtr', 'FKN Zero', 'Kaseko Fánboy', 'sadds', 'lazyno', 'Dont flam3 m3', 'AceINDUSTRY', 'Daddy Amnesia', 'Mylederace', 'R1ZA', 'Rizztard Goddess', '170294', 'WhiTe D LoTuS', 'rocketleague', 'boyishpear24', 'fjvidal13', 'VaiiiNz', 'locura2', 'jerzyk333v3', 'Zuguciola', 'lilDigiritter', 'YASU01', 'Pirate Pyke', 'aarrccangee', 'T0UT NUNU', 'SeirEast', 'lroh', 'DioVerserk', 'ValeMX', '5181', 'SATANA SEASON', 'OyeFrancis', 'GeniusOfTheSky', 'FIM ArminArm', 'ILoveToDrinkMilk', 'FORCED T0 PLAY', 'KVZY', 'HamAdá', 'itiswhâtitis', 'Tomatuspapas', 'OmiPumi', 'Rambales', 'Suhkar', '3Fakker1', 'The Fudge Factor', 'MaDStark', 'Onessun', 'Uncle Yasu0', 'Wavry', 'Scwhappes', 'FusedForces', 'eRcø', 'OMG ITS SARRIX', 'TryXr', 'ExodiasRCheek', 'Tactical TRex', 'klimpo', 'PermaBanSamurai', 'OnlyPlay4KDA', 'Meduolis1337', 'Civil Engineer 1', 'AFRIKAN SAPORTO', 'Catatangas', 'DragonBeatss', 'QuajutsuI', 'DarkWorrir', 'xArcher', 'ÂKKURT', 'staarisback', 'Monkey D LeFeed', 'hamzaab123', 'catchafizz', 'Zoltas', 'tretunn', 'Shinobi of dark', 'FAM3S1', 'Nosfomi', 'The Mango Loco', 'The1VeN0M', 'Ulysse310', 'Kíper', 'Tschaenick', 'Gandalo', 'Shi nο kage', 'trentjeuh', 'GetBanned14Days', 'BingooFlamingo', 'S1lentFox', 'cherrymcgerry', 'FlyingToTheMoon', 'T3v3zz', 'Chatouw is gay', 'Xavier1426', 'NewZeeFyr', 'WhyShacoBan', 'theking287363', 'Étrangers Dehors', 'Vivemarinejtm', 'PykOni', 'JavitoJr7', 'Capra Lord', 'III II S 2 3', 'JaviiCarried', 'crÿ me a rïven', 'ting goes skraaa', 'SBS KiketteUwU', 'VICENTSUKE', 'BLUE LABELL', 'joschua', 'Freîheit', 'Ciccantonio', 'Saber Ałter', 'aspitouf', 'smurphhh', 'gingrr', 'Leif Terje', 'Internal Affairs', 'MrTrash', 'TheGingerOne69', 'WatsonBadAss', 'AlpachoDarkO', 'Falcao Radamel', 'Δssassadin', 'sauce dou brazil', 'Sénioro Rengar', 'DondurmaCiger', 'Surfer Panda', 'LIL BO SLOUPI', 'Dalaco99', 'FREE PALEST11NE', 'NAVVVVVVVVV', 'ShruiKan15', 'Sophisttsoul', 'Daddy Doola', 'DeusFlammae', 'Cuttix99', 'Sidiius', 'Pipopu', 'Δ God Δ', 'Midir', 'TheKinnGG', 'werfetLOL', 'Faikheure', 'Cuckson', 'killbill9898', 'JustOneMorePlate', 'Duo queue abuser', 'SNV Don Con', 'homeryxxx', 'Z TK', 'Ehrenpapa Ornn', 'SKP Jonyyy', 'WatiTrittleiter', 'gagat89', 'Hí im Phantom', 'Gonzarioo', 'AlissHale', 'Jovel126', 'UmbraWitchCereza', 'DKS Bjon', 'MB zaza', 'guachafita', 'BELABBES', 'Misdo Bagarre', 'Gongαs', 'ººVoywyesu JRºº', 'theBAUSFSS', 'Ksenokles', 'Lastßreath', 'Miss Cupcaké', 'chamaluxe', 'Singed Guy', 'Träce', 'I Kiss Lolis', 'Jesus is adc', 'Gwentanari', 'oversnakefr', 'TaylorSwift189', 'Déménageur', 'Legendary Alda', 'Rauf', 'BigPDom', 'Pascowcow', 'Yfrozzz v2', 'WidowMaker16', 'Rei Saino', 'Arribasland', 'HOW TO BE YOU PO', 'LohrPT', 'GlowSnow', 'JEANPIERRRRRREE', 'Snake Xenzia', 'Mikoa', 'Death Zulit', 'ZuiioGHi', 'RebeuTBMreçoit', 'Essek Thelyss', 'EL Super', 'keep safe farm', 'TSM LARS', 'Aitor2004', 'Mighty Titi', 'BG JaYxsE', 'killingxpry', 'VN BMW X6', 'Znayed', 'Her CosmicLion', 'popomu elleyin', 'ABODAN', 'Øya', 'karimeto', 'The Lôrd Of Dawn', 'RCSPPlays', 'Baesti', 'Coronel Manudo', 'jagafragga', '2muchJohn', 'Tibabz', 'Ð Pedro Ð', 'HammerHD', 'Cassiopé', 'Vamos Atleti', 'depression life', 'igdrasiel', 'Åshy', 'Draven on Eva 01', 'xxMhars', 'LERichter', 'blaster33559', 'SugàR DàddYY', 'h2dwillem', 'MaJuOrS', 'runnerseb', 'Juodas Pikachu', 'GEN Nussfüllung', 'D3 Martino', 'xavega888', 'hαo', 'Dhû l Qarnayn', 'KG Mikelly', 'crossblade1', 'iHateMonkeyz', 'Jola310', 'R0b1n2k3', 'Jean peuplù', 'xTchiko', 'effe2icsse', 'Sillandsmurflord', 'QQ Hard adc', 'main warwick', 'sofixxwiedu', 'Maximus Yordles', 'Abandon AII Hope', 'SAKEN no ikiko', 'PabloAguilarLoL', 'Wintrade Jungler', 'BillsyBob', 'SkrrtSkrrtSkrrt', 'Rugod', 'CurryMaker5', 'WTFitsSHU', 'Bancy', 'LeDorsch24', 'vivass', 'RDK Figuel', 'My Elo Will Ryze', '0blackcate0', 'ANDI BAITEMAN', 'PLANsero420', 'Urıεl', 'ROHNEN1', 'Hìde On Script', 'VirTuaLToRaN6207', 'ryoichie', 'yumi357', 'EerenOne', 'Δrkein', 'Billel QLF', 'GHØŠŤ', 'Hartwurst Harald', 'Skillpander', 'Andoloria', 'StΣph Curry 30', 'GordaTriste', 'Infuz', 'TakingLafterL', 'Ruudik', 'Ðevil Draven', 'ûnknôwn', 'HV MONGRELL', 'Nightshadeeee', 'FATVIRGIN123', 'ShanksLeRouxmain', 'Mias Khalifa', '5darknight', 'GoodLuk YR Fuked']\n"
     ]
    }
   ],
   "source": [
    "def get_summoner_names_from_csv(file_path):\n",
    "    summoner_names = []\n",
    "    \n",
    "    with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            summoner_names.append(row['summonerName'])\n",
    "    \n",
    "    return summoner_names\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "file_path = '../DataProcessing/TestData/PLATINUM_players.csv'\n",
    "summoner_names = get_summoner_names_from_csv(file_path)\n",
    "print(summoner_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f873ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 38/1014 summoner names processed.\n",
      "Progress: 75/1014 summoner names processed.\n",
      "Progress: 112/1014 summoner names processed.\n",
      "Progress: 150/1014 summoner names processed.\n",
      "Progress: 188/1014 summoner names processed.\n",
      "Progress: 225/1014 summoner names processed.\n",
      "Progress: 262/1014 summoner names processed.\n",
      "Progress: 299/1014 summoner names processed.\n",
      "Progress: 337/1014 summoner names processed.\n",
      "Progress: 375/1014 summoner names processed.\n",
      "Progress: 413/1014 summoner names processed.\n",
      "Progress: 451/1014 summoner names processed.\n",
      "Progress: 489/1014 summoner names processed.\n",
      "Progress: 527/1014 summoner names processed.\n",
      "Progress: 565/1014 summoner names processed.\n",
      "Progress: 603/1014 summoner names processed.\n",
      "Progress: 641/1014 summoner names processed.\n",
      "Progress: 678/1014 summoner names processed.\n",
      "Progress: 716/1014 summoner names processed.\n",
      "Progress: 753/1014 summoner names processed.\n",
      "Progress: 791/1014 summoner names processed.\n",
      "Progress: 828/1014 summoner names processed.\n",
      "Progress: 866/1014 summoner names processed.\n",
      "Progress: 904/1014 summoner names processed.\n",
      "Progress: 942/1014 summoner names processed.\n",
      "Progress: 980/1014 summoner names processed.\n",
      "Progress: 1014/1014 summoner names processed. Update complete.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "#FINDS PUUID FROM SUMMONER NAME\n",
    "def update_summoner_names_with_puuid(file_path, summoner_names):\n",
    "    api_key = \"RGAPI-b8c6b8bc-cae0-444d-b593-c5795065be0d\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"da-DK,da;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "        \"Accept-Charset\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\": \"https://developer.riotgames.com\",\n",
    "        \"X-Riot-Token\": api_key\n",
    "    }\n",
    "    summoner_to_puuid = {}\n",
    "\n",
    "    start_time = time.time()\n",
    "    last_update_time = start_time\n",
    "    total_names = len(summoner_names)\n",
    "    names_processed = 0\n",
    "\n",
    "    # Fetch puuid for each summoner name\n",
    "    for name in summoner_names:\n",
    "        url = f\"https://euw1.api.riotgames.com/lol/summoner/v4/summoners/by-name/{name}\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            summoner_to_puuid[name] = data['puuid']\n",
    "        else:\n",
    "            print(f\"Error fetching data for {name}: {response.status_code}\")\n",
    "        names_processed += 1\n",
    "        current_time = time.time()\n",
    "\n",
    "        # Check if 1 minute has passed for progress update\n",
    "        if current_time - last_update_time >= 60:\n",
    "            print(f\"Progress: {names_processed}/{total_names} summoner names processed.\")\n",
    "            last_update_time = current_time\n",
    "\n",
    "        time.sleep(1.5)  # Delay to comply with rate limit\n",
    "    \n",
    "    # Update progress after finishing all requests\n",
    "    print(f\"Progress: {names_processed}/{total_names} summoner names processed. Update complete.\")\n",
    "\n",
    "    # Now, replace summoner names with puuid in the CSV\n",
    "    temp_file_path = file_path + \".tmp\"\n",
    "    with open(file_path, mode='r', encoding='utf-8') as infile, open(temp_file_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in reader:\n",
    "            if row['summonerName'] in summoner_to_puuid:\n",
    "                row['summonerName'] = summoner_to_puuid[row['summonerName']]\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    # Replace original file with the updated temp file\n",
    "    os.replace(temp_file_path, file_path)\n",
    "\n",
    "\n",
    "# Call the function\n",
    "update_summoner_names_with_puuid(file_path, summoner_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac6e12b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import csv\n",
    "import os\n",
    "from aiohttp import ClientSession\n",
    "#FINDS PUUID FROM SUMMONER NAME v2\n",
    "async def fetch_puuid(session, url, headers, semaphore, summoner_to_puuid, name):\n",
    "    async with semaphore:\n",
    "        async with session.get(url, headers=headers) as response:\n",
    "            if response.status == 200:\n",
    "                data = await response.json()\n",
    "                summoner_to_puuid[name] = data['puuid']\n",
    "            else:\n",
    "                print(f\"Error fetching data for {name}: {response.status}\")\n",
    "\n",
    "async def rate_limited_requester(summoner_names, headers, rate_limit=30):\n",
    "    tasks = []\n",
    "    summoner_to_puuid = {}\n",
    "\n",
    "    semaphore = asyncio.Semaphore(rate_limit)\n",
    "\n",
    "    async with ClientSession() as session:\n",
    "        for name in summoner_names:\n",
    "            url = f\"https://euw1.api.riotgames.com/lol/summoner/v4/summoners/by-name/{name}\"\n",
    "            task = asyncio.create_task(fetch_puuid(session, url, headers, semaphore, summoner_to_puuid, name))\n",
    "            tasks.append(task)\n",
    "\n",
    "            if len(tasks) % rate_limit == 0:\n",
    "                await asyncio.sleep(1)\n",
    "\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "    return summoner_to_puuid\n",
    "\n",
    "async def update_summoner_names_with_puuid(file_path, summoner_names):\n",
    "    api_key = \"RGAPI-e75b46d3-5e51-4829-b978-68790c3ebf56\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"da-DK,da;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "        \"Accept-Charset\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\": \"https://developer.riotgames.com\",\n",
    "        \"X-Riot-Token\": api_key\n",
    "    }\n",
    "\n",
    "    summoner_to_puuid = await rate_limited_requester(summoner_names, headers)\n",
    "\n",
    "    temp_file_path = file_path + \".tmp\"\n",
    "    with open(file_path, mode='r', encoding='utf-8') as infile, open(temp_file_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        writer = csv.DictWriter(outfile, fieldnames=reader.fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in reader:\n",
    "            if row['summonerName'] in summoner_to_puuid:\n",
    "                row['summonerName'] = summoner_to_puuid[row['summonerName']]\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    os.replace(temp_file_path, file_path)\n",
    "\n",
    "# Execution block adapted for Jupyter Notebook\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "source_csv_path = \"../DataProcessing/TestData/GOLD_players.csv\"\n",
    "\n",
    "\n",
    "if loop.is_running():\n",
    "    task = loop.create_task(update_summoner_names_with_puuid(source_csv_path, summoner_names))\n",
    "else:\n",
    "    loop.run_until_complete(update_summoner_names_with_puuid(source_csv_path, summoner_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecf2cb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 38 summoners processed.\n",
      "Progress: 75 summoners processed.\n",
      "Progress: 112 summoners processed.\n",
      "Progress: 149 summoners processed.\n",
      "Progress: 186 summoners processed.\n",
      "Progress: 223 summoners processed.\n",
      "Progress: 260 summoners processed.\n",
      "Progress: 297 summoners processed.\n",
      "Progress: 334 summoners processed.\n",
      "Progress: 371 summoners processed.\n",
      "Progress: 408 summoners processed.\n",
      "Progress: 445 summoners processed.\n",
      "Progress: 482 summoners processed.\n",
      "Progress: 519 summoners processed.\n",
      "Progress: 556 summoners processed.\n",
      "Progress: 593 summoners processed.\n",
      "Progress: 630 summoners processed.\n",
      "Progress: 667 summoners processed.\n",
      "Progress: 704 summoners processed.\n",
      "Progress: 741 summoners processed.\n",
      "Progress: 778 summoners processed.\n",
      "Progress: 815 summoners processed.\n",
      "Progress: 852 summoners processed.\n",
      "Progress: 889 summoners processed.\n",
      "Progress: 926 summoners processed.\n",
      "Progress: 963 summoners processed.\n",
      "Progress: 1000 summoners processed.\n",
      "Final Progress: 1014 summoners processed. Task complete.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "#Finds matches from puuid\n",
    "def fetch_matches_and_save(source_csv_path, target_csv_path):\n",
    "    api_key = \"RGAPI-b8c6b8bc-cae0-444d-b593-c5795065be0d\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"da-DK,da;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "        \"Accept-Charset\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\": \"https://developer.riotgames.com\",\n",
    "        \"X-Riot-Token\": api_key\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    last_update_time = start_time\n",
    "    summoners_processed = 0\n",
    "\n",
    "    # Ensure the target file directory exists\n",
    "    os.makedirs(os.path.dirname(target_csv_path), exist_ok=True)\n",
    "\n",
    "    with open(source_csv_path, mode='r', encoding='utf-8') as infile, open(target_csv_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "        csv_reader = csv.DictReader(infile)\n",
    "        csv_writer = csv.writer(outfile)\n",
    "        csv_writer.writerow(['MatchID'])  # Header for target CSV\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            puuid = row['summonerName']  # Assuming this column actually contains puuids\n",
    "            url = f\"https://europe.api.riotgames.com/lol/match/v5/matches/by-puuid/{puuid}/ids?type=ranked&start=0&count=20\"\n",
    "            response = requests.get(url, headers=headers)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                match_ids = response.json()\n",
    "                for match_id in match_ids:\n",
    "                    csv_writer.writerow([match_id])\n",
    "            else:\n",
    "                print(f\"Error fetching matches for {puuid}: {response.status_code}\")\n",
    "            \n",
    "            summoners_processed += 1\n",
    "            current_time = time.time()\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(1.5)\n",
    "            \n",
    "            # Print progress every minute\n",
    "            if current_time - last_update_time >= 60:\n",
    "                print(f\"Progress: {summoners_processed} summoners processed.\")\n",
    "                last_update_time = current_time\n",
    "\n",
    "    # Final progress update\n",
    "    print(f\"Final Progress: {summoners_processed} summoners processed. Task complete.\")\n",
    "\n",
    "# Example usage\n",
    "source_csv_path = '../DataProcessing/TestData/PLATINUM_players.csv'\n",
    "target_csv_path = '../DataProcessing/TestData/PLATINUM_GAMES.csv'\n",
    "fetch_matches_and_save(source_csv_path, target_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e971190d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n",
      "Error: 400\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import csv\n",
    "import os\n",
    "from aiohttp import ClientSession\n",
    "import datetime\n",
    "\n",
    "async def fetch_match_ids(session, url, csv_writer, sem, progress):\n",
    "    async with sem:\n",
    "        async with session.get(url) as response:\n",
    "            if response.status == 200:\n",
    "                match_ids = await response.json()\n",
    "                for match_id in match_ids:\n",
    "                    csv_writer.writerow([match_id])\n",
    "                progress['count'] += 1  # Increment the progress count for each successful fetch\n",
    "            else:\n",
    "                print(f\"Error: {response.status}\")\n",
    "\n",
    "async def run(source_csv_path, target_csv_path, api_key):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"da-DK,da;q=0.9,en-US;q=0.8,en;q=0.7\",\n",
    "        \"Accept-Charset\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "        \"Origin\": \"https://developer.riotgames.com\",\n",
    "        \"X-Riot-Token\": api_key\n",
    "    }\n",
    "    \n",
    "    sem = asyncio.Semaphore(30)  # Control concurrency to 30 requests per second\n",
    "    progress = {'count': 0, 'last_update': datetime.datetime.now()}  # Initialize progress tracking\n",
    "\n",
    "    # Ensure the target file directory exists\n",
    "    os.makedirs(os.path.dirname(target_csv_path), exist_ok=True)\n",
    "\n",
    "    # Open the target CSV file outside of the async context\n",
    "    with open(target_csv_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "        csv_writer = csv.writer(outfile)\n",
    "        csv_writer.writerow(['MatchID'])  # Writing header for match IDs\n",
    "\n",
    "        async with ClientSession(headers=headers) as session:\n",
    "            tasks = []\n",
    "            with open(source_csv_path, mode='r', encoding='utf-8') as infile:\n",
    "                csv_reader = csv.DictReader(infile)\n",
    "                for row in csv_reader:\n",
    "                    puuid = row['summonerName']\n",
    "                    url = f\"https://europe.api.riotgames.com/lol/match/v5/matches/by-puuid/{puuid}/ids?type=ranked&start=0&count=20\"\n",
    "                    task = asyncio.create_task(fetch_match_ids(session, url, csv_writer, sem, progress))\n",
    "                    tasks.append(task)\n",
    "                    \n",
    "                    # Check and print progress approximately every minute\n",
    "                    if (datetime.datetime.now() - progress['last_update']).seconds >= 60:\n",
    "                        print(f\"Progress: {progress['count']} summonerNames processed at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "                        progress['last_update'] = datetime.datetime.now()\n",
    "\n",
    "                    if len(tasks) >= 30:\n",
    "                        await asyncio.gather(*tasks)\n",
    "                        tasks = []  # Reset the list of tasks after processing\n",
    "                        await asyncio.sleep(1)  # Ensure we don't exceed 30 requests per second\n",
    "\n",
    "                # Await any remaining tasks\n",
    "                if tasks:\n",
    "                    await asyncio.gather(*tasks)\n",
    "\n",
    "                # Final progress update\n",
    "                print(f\"Final Progress: {progress['count']} summonerNames processed at {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Example usage\n",
    "source_csv_path = '../DataProcessing/TestData/GOLD_players.csv'\n",
    "target_csv_path = '../DataProcessing/TestData/GOLD_GAMES.csv'\n",
    "api_key = \"RGAPI-e75b46d3-5e51-4829-b978-68790c3ebf56\"\n",
    "\n",
    "# Adapting to environments with an existing event loop\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "if loop.is_running():\n",
    "    task = loop.create_task(run(source_csv_path, target_csv_path, api_key))\n",
    "else:\n",
    "    loop.run_until_complete(run(source_csv_path, target_csv_path, api_key))\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e21f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
